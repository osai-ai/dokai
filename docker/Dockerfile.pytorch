FROM dokai:base

ENV TORCH_CUDA_ARCH_LIST "6.0;6.1;7.0;7.5;8.0;8.6;8.9;9.0"

# Install TensorRT GA and build TensorRT OSS
RUN wget -nv https://developer.nvidia.com/downloads/compute/machine-learning/tensorrt/secure/9.1.0/tars/tensorrt-9.1.0.4.linux.x86_64-gnu.cuda-12.2.tar.gz && \
    tar -xf tensorrt-9.1.0.4.linux.x86_64-gnu.cuda-12.2.tar.gz && \
    cp -a TensorRT-9.1.0.4/lib/*.so* /usr/lib/x86_64-linux-gnu && \
    cp -a TensorRT-9.1.0.4/include/*.h /usr/include/x86_64-linux-gnu && \
    pip3 install TensorRT-9.1.0.4/python/tensorrt-9.1.0.post12.dev4-cp311-none-linux_x86_64.whl && \
    pip3 install TensorRT-9.1.0.4/onnx_graphsurgeon/onnx_graphsurgeon-0.4.0-py2.py3-none-any.whl && \
    rm -rf TensorRT-9.1.0.4 tensorrt-9.1.0.4.linux.x86_64-gnu.cuda-12.2.tar.gz && \
    git clone --depth=1 --branch=v9.1.0 --single-branch https://github.com/nvidia/TensorRT && \
    cd TensorRT && \
    git submodule sync && git submodule update --init --recursive && \
    mkdir -p build && cd build && \
    cmake .. -DGPU_ARCHS="60 61 70 75 80 86 89 90" -DBUILD_SAMPLES=ON \
    -DTRT_LIB_DIR=/usr/lib/x86_64-linux-gnu \
    -DTRT_OUT_DIR=/usr/lib/x86_64-linux-gnu \
    -DCUDNN_ROOT_DIR=/usr/lib/x86_64-linux-gnu && \
    make -j$(nproc) && \
    cd ../.. && rm -rf TensorRT && \
    ln -s /usr/lib/x86_64-linux-gnu/trtexec /usr/bin/trtexec && \
    apt-get clean && \
    apt-get -y autoremove && \
    rm -rf /var/lib/apt/lists/* && \
    rm -rf /var/cache/apt/archives/*
ENV LD_LIBRARY_PATH "${LD_LIBRARY_PATH}:/usr/lib/x86_64-linux-gnu"

# Build MAGMA
COPY docker/magma/make.inc make.inc
RUN MAGMA_VERSION=2.7.1 && \
    ln -s /usr/local/cuda/lib64/libcudart.so /usr/lib/libcudart.so && \
    wget -nv https://bitbucket.org/icl/magma/get/v${MAGMA_VERSION}.tar.gz && \
    mkdir magma-${MAGMA_VERSION}/ && \
    tar -xzf v${MAGMA_VERSION}.tar.gz -C magma-${MAGMA_VERSION}/ --strip-components=1 && \
    cp make.inc magma-${MAGMA_VERSION} && \
    cd magma-${MAGMA_VERSION} && \
    make -j$(nproc) && make install && \
    cd .. && rm -rf magma-${MAGMA_VERSION} v${MAGMA_VERSION}.tar.gz make.inc

# Install PyTorch
RUN git clone --depth=1 --branch=v2.1.0 --single-branch https://github.com/pytorch/pytorch.git && \
    cd pytorch && \
    git submodule sync && git submodule update --init --recursive && \
    TORCH_NVCC_FLAGS="-Xfatbin -compress-all" python3 setup.py install && \
    cd .. && rm -rf pytorch

# Install Torch-TensorRT
COPY docker/torchtrt/WORKSPACE WORKSPACE
RUN git clone --depth=1 --branch=v2.1.0-rc3 --single-branch https://github.com/pytorch/TensorRT.git && \
    cp WORKSPACE TensorRT/ && cd TensorRT && \
    bazel build //:libtorchtrt --compilation_mode opt && \
    python3 setup.py install --use-cxx11-abi && \
    cd .. && rm -rf TensorRT WORKSPACE

# Install torchvision
RUN git clone --depth=1 --branch=v0.16.0 --single-branch https://github.com/pytorch/vision.git && \
    cd vision && \
    FORCE_CUDA=1 TORCHVISION_USE_FFMPEG=0 python3 setup.py install && \
    cd .. && rm -rf vision

# Install torchaudio
RUN git clone --depth=1 --branch=v2.1.0 --single-branch https://github.com/pytorch/audio.git && \
    cd audio && \
    git submodule sync && git submodule update --init --recursive && \
    python3 setup.py install && \
    cd .. && rm -rf audio

# Install GPU and DL packages
RUN pip3 install --no-cache-dir \
    triton==2.1.0 \
    cupy-cuda12x==12.2.0 \
    pytorch-ignite==0.4.12 \
    pytorch-argus==1.0.0 \
    kornia==0.7.0 \
    timm==0.9.8 \
    onnx==1.14.1 \
    onnxruntime==1.16.1 \
    onnxsim==0.4.34
